{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a0780df-d9fa-43db-bb58-bdd0a48e19d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Courses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8ea72d5-73b6-4035-b5b3-52f4d1b86dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Courses.csv\")\n",
    "\n",
    "# 1. Remove specified columns\n",
    "columns_to_remove = ['nplay_video', 'incomplete_flag', 'roles']\n",
    "df_cleaned = df.drop(columns=columns_to_remove)\n",
    "\n",
    "# 2. Handle missing values\n",
    "# For categorical variables (LoE_DI) - impute with mode\n",
    "df_cleaned['LoE_DI'] = df_cleaned['LoE_DI'].fillna(df_cleaned['LoE_DI'].mode()[0])\n",
    "\n",
    "# For gender in random way\n",
    "missing_indices = df_cleaned[df_cleaned['gender'].isnull()].index\n",
    "df_cleaned.loc[missing_indices, 'gender'] = np.random.choice(df_cleaned['gender'].dropna(), len(missing_indices))\n",
    "\n",
    "# For YoB - impute with median\n",
    "df_cleaned['YoB'] = df_cleaned['YoB'].fillna(df_cleaned['YoB'].median())\n",
    "\n",
    "# 3. Drop rows with missing grades\n",
    "df_cleaned = df_cleaned.dropna(subset=['grade'])\n",
    "\n",
    "# 5. Define function for nchapters imputation\n",
    "def impute_nchapters_simple(df):\n",
    "    # Create copy of original nchapters\n",
    "    df['nchapters_imputed'] = df['nchapters'].copy()\n",
    "    \n",
    "    # Imputation logic based on certification and activity days\n",
    "    mask = df['nchapters'].isna()\n",
    "    \n",
    "    conditions = [\n",
    "        # Condition 1: Certified students\n",
    "        (mask) & (df['certified'] == 1),\n",
    "        # Condition 2: Not certified but active (ndays_act > 3)\n",
    "        (mask) & (df['certified'] == 0) & (df['ndays_act'] > 3),\n",
    "        # Condition 3: Not certified and some activity (ndays_act <= 3)\n",
    "        (mask) & (df['certified'] == 0) & (df['ndays_act'] <= 3),\n",
    "        # Condition 4: No activity recorded (ndays_act is NaN) but viewed course\n",
    "        (mask) & (df['ndays_act'].isna()) & (df['viewed'] == 1),\n",
    "        # Condition 5: No activity and never viewed (complete non-engagement)\n",
    "        (mask) & (df['ndays_act'].isna()) & (df['viewed'] == 0)\n",
    "    ]\n",
    "    \n",
    "    values = [\n",
    "        16,  # Average for certified students\n",
    "        3,   # Average for non-certified active students\n",
    "        1,   # Minimal engagement\n",
    "        1,   # Viewed but no sustained activity\n",
    "        0    # Never engaged with content\n",
    "    ]\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Apply imputation\n",
    "    df['nchapters_imputed'] = np.select(conditions, values, df['nchapters_imputed'])\n",
    "    \n",
    "    return df['nchapters_imputed']\n",
    "\n",
    "# Apply nchapters imputation\n",
    "df_cleaned['nchapters_imputed'] = impute_nchapters_simple(df_cleaned)\n",
    "\n",
    "# 6. nevents missing data\n",
    "def impute_nevents(row):\n",
    "    if pd.isna(row['nevents']):  # Only impute if the value is missing\n",
    "        if row['nchapters'] == 0:\n",
    "            return 0\n",
    "        elif row['nchapters'] == 1:\n",
    "            return np.random.choice([0, 1], p=[0.7, 0.3])\n",
    "        elif 2 <= row['nchapters'] <= 5:\n",
    "            return np.random.choice([0, 1, 2], p=[0.5, 0.3, 0.2])\n",
    "        elif 6 <= row['nchapters'] <= 12:\n",
    "            return np.random.choice([1, 2, 3], p=[0.4, 0.4, 0.2])\n",
    "        else:\n",
    "            return np.random.choice([2, 3, 4], p=[0.3, 0.4, 0.3])\n",
    "    else:\n",
    "        return row['nevents']  # Return original value if not missing\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create new column with imputed values\n",
    "df_cleaned['nevents_imputed'] = df_cleaned.apply(impute_nevents, axis=1)\n",
    "\n",
    "# 7. Save the cleaned dataset with all changes\n",
    "df_cleaned.to_csv('cleaned_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dbdb7bb-4d1c-45a7-8410-a55ec8a934e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset Overview ===\n",
      "Number of rows: 592766\n",
      "Number of columns: 19\n",
      "\n",
      "=== Data Types ===\n",
      "course_id             object\n",
      "userid_DI             object\n",
      "registered             int64\n",
      "viewed                 int32\n",
      "explored               int32\n",
      "certified              int32\n",
      "final_cc_cname_DI     object\n",
      "LoE_DI                object\n",
      "YoB                  float64\n",
      "gender                object\n",
      "grade                float64\n",
      "start_time_DI         object\n",
      "last_event_DI         object\n",
      "nevents              float64\n",
      "ndays_act            float64\n",
      "nchapters            float64\n",
      "nforum_posts           int64\n",
      "nchapters_imputed    float64\n",
      "nevents_imputed      float64\n",
      "dtype: object\n",
      "\n",
      "=== Basic Statistics ===\n",
      "       registered         viewed       explored      certified            YoB  \\\n",
      "count    592766.0  592766.000000  592766.000000  592766.000000  592766.000000   \n",
      "mean          1.0       0.631195       0.065592       0.029838    1985.637746   \n",
      "std           0.0       0.482481       0.247569       0.170141       8.254398   \n",
      "min           1.0       0.000000       0.000000       0.000000    1931.000000   \n",
      "25%           1.0       0.000000       0.000000       0.000000    1983.000000   \n",
      "50%           1.0       1.000000       0.000000       0.000000    1988.000000   \n",
      "75%           1.0       1.000000       0.000000       0.000000    1991.000000   \n",
      "max           1.0       1.000000       1.000000       1.000000    2013.000000   \n",
      "\n",
      "               grade        nevents      ndays_act      nchapters  \\\n",
      "count  592766.000000  404323.000000  436674.000000  355995.000000   \n",
      "mean        0.033477     459.783658       5.940519       3.689291   \n",
      "std         0.150336    1576.711332      12.263307       4.568059   \n",
      "min         0.000000       1.000000       1.000000       1.000000   \n",
      "25%         0.000000       3.000000       1.000000       1.000000   \n",
      "50%         0.000000      25.000000       2.000000       2.000000   \n",
      "75%         0.000000     169.000000       5.000000       4.000000   \n",
      "max         1.010000  197757.000000     205.000000      48.000000   \n",
      "\n",
      "        nforum_posts  nchapters_imputed  nevents_imputed  \n",
      "count  592766.000000      592766.000000    592766.000000  \n",
      "mean        0.019660           2.482610       314.267035  \n",
      "std         0.234847           3.856483      1319.520614  \n",
      "min         0.000000           0.000000         0.000000  \n",
      "25%         0.000000           1.000000         2.000000  \n",
      "50%         0.000000           1.000000         4.000000  \n",
      "75%         0.000000           2.000000        68.000000  \n",
      "max        20.000000          48.000000    197757.000000  \n",
      "\n",
      "=== Missing Values ===\n",
      "course_id                 0\n",
      "userid_DI                 0\n",
      "registered                0\n",
      "viewed                    0\n",
      "explored                  0\n",
      "certified                 0\n",
      "final_cc_cname_DI         0\n",
      "LoE_DI                    0\n",
      "YoB                       0\n",
      "gender                    0\n",
      "grade                     0\n",
      "start_time_DI             0\n",
      "last_event_DI        169903\n",
      "nevents              188443\n",
      "ndays_act            156092\n",
      "nchapters            236771\n",
      "nforum_posts              0\n",
      "nchapters_imputed         0\n",
      "nevents_imputed           0\n",
      "dtype: int64\n",
      "\n",
      "=== Sample of First Few Rows ===\n",
      "                    course_id       userid_DI  registered  viewed  explored  \\\n",
      "0  HarvardX/CB22x/2013_Spring  MHxPC130442623           1       0         0   \n",
      "1         HarvardX/CS50x/2012  MHxPC130442623           1       1         0   \n",
      "2  HarvardX/CB22x/2013_Spring  MHxPC130275857           1       0         0   \n",
      "3         HarvardX/CS50x/2012  MHxPC130275857           1       0         0   \n",
      "4  HarvardX/ER22x/2013_Spring  MHxPC130275857           1       0         0   \n",
      "\n",
      "   certified final_cc_cname_DI      LoE_DI     YoB gender  grade  \\\n",
      "0          0     United States  Bachelor's  1988.0      f    0.0   \n",
      "1          0     United States  Bachelor's  1988.0      m    0.0   \n",
      "2          0     United States  Bachelor's  1988.0      m    0.0   \n",
      "3          0     United States  Bachelor's  1988.0      m    0.0   \n",
      "4          0     United States  Bachelor's  1988.0      f    0.0   \n",
      "\n",
      "  start_time_DI last_event_DI  nevents  ndays_act  nchapters  nforum_posts  \\\n",
      "0    2012-12-19    2013-11-17      NaN        9.0        NaN             0   \n",
      "1    2012-10-15           NaN      NaN        9.0        1.0             0   \n",
      "2    2013-02-08    2013-11-17      NaN       16.0        NaN             0   \n",
      "3    2012-09-17           NaN      NaN       16.0        NaN             0   \n",
      "4    2012-12-19           NaN      NaN       16.0        NaN             0   \n",
      "\n",
      "   nchapters_imputed  nevents_imputed  \n",
      "0                3.0              3.0  \n",
      "1                1.0              1.0  \n",
      "2                3.0              4.0  \n",
      "3                3.0              3.0  \n",
      "4                3.0              2.0  \n",
      "\n",
      "=== Binary Columns Distribution ===\n",
      "\n",
      "viewed value counts:\n",
      "viewed\n",
      "1    63.1\n",
      "0    36.9\n",
      "Name: proportion, dtype: float64 %\n",
      "\n",
      "explored value counts:\n",
      "explored\n",
      "0    93.4\n",
      "1     6.6\n",
      "Name: proportion, dtype: float64 %\n",
      "\n",
      "certified value counts:\n",
      "certified\n",
      "0    97.0\n",
      "1     3.0\n",
      "Name: proportion, dtype: float64 %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df_cleaned = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "# Convert to numeric and handle NaN values\n",
    "df_cleaned['viewed'] = pd.to_numeric(df_cleaned['viewed'], errors='coerce').fillna(0).astype(int)\n",
    "df_cleaned['explored'] = pd.to_numeric(df_cleaned['explored'], errors='coerce').fillna(0).astype(int)\n",
    "df_cleaned['certified'] = pd.to_numeric(df_cleaned['certified'], errors='coerce').fillna(0).astype(int)\n",
    "df_cleaned['grade'] = pd.to_numeric(df_cleaned['grade'], errors='coerce').fillna(0)\n",
    "df_cleaned['nevents_imputed'] = pd.to_numeric(df_cleaned['nevents_imputed'], errors='coerce').fillna(0)\n",
    "df_cleaned['nchapters_imputed'] = pd.to_numeric(df_cleaned['nchapters_imputed'], errors='coerce').fillna(0)\n",
    "\n",
    "# Convert ID columns to strings\n",
    "df_cleaned['userid_DI'] = df_cleaned['userid_DI'].astype(str)\n",
    "df_cleaned['course_id'] = df_cleaned['course_id'].astype(str)\n",
    "\n",
    "# Save the updated dataset\n",
    "df_cleaned.to_csv('cleaned_dataset.csv', index=False)\n",
    "\n",
    "# Let's analyze the dataset\n",
    "print(\"\\n=== Dataset Overview ===\")\n",
    "print(f\"Number of rows: {len(df_cleaned)}\")\n",
    "print(f\"Number of columns: {len(df_cleaned.columns)}\")\n",
    "print(\"\\n=== Data Types ===\")\n",
    "print(df_cleaned.dtypes)\n",
    "\n",
    "print(\"\\n=== Basic Statistics ===\")\n",
    "print(df_cleaned.describe())\n",
    "\n",
    "print(\"\\n=== Missing Values ===\")\n",
    "print(df_cleaned.isnull().sum())\n",
    "\n",
    "print(\"\\n=== Sample of First Few Rows ===\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Additional analysis for binary columns\n",
    "binary_cols = ['viewed', 'explored', 'certified']\n",
    "print(\"\\n=== Binary Columns Distribution ===\")\n",
    "for col in binary_cols:\n",
    "    print(f\"\\n{col} value counts:\")\n",
    "    print(df_cleaned[col].value_counts(normalize=True).round(3) * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f441e61-6d72-4e4f-966f-d9c4b7eb6f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.5.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf57385-9898-4ceb-a7eb-3eb99e92ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CourseRecommendationALS\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Convert pandas DataFrame to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(data)\n",
    "\n",
    "# Rename columns to match Spark's ALS expected column names\n",
    "spark_df = spark_df.withColumnRenamed('user_index', 'userId')\n",
    "spark_df = spark_df.withColumnRenamed('course_index', 'itemId')\n",
    "spark_df = spark_df.withColumnRenamed('nevents_imputed', 'rating')\n",
    "\n",
    "# Ensure columns are integer types\n",
    "spark_df = spark_df.withColumn('userId', spark_df['userId'].cast('integer'))\n",
    "spark_df = spark_df.withColumn('itemId', spark_df['itemId'].cast('integer'))\n",
    "spark_df = spark_df.withColumn('rating', spark_df['rating'].cast('float'))\n",
    "\n",
    "# Split data into training and test sets\n",
    "(train, test) = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Initialize ALS model\n",
    "als = ALS(\n",
    "    maxIter=20,\n",
    "    regParam=0.1,\n",
    "    rank=20,\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"itemId\",\n",
    "    ratingCol=\"rating\",\n",
    "    implicitPrefs=True,\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model = als.fit(train)\n",
    "\n",
    "# Generate top 5 course recommendations for each user\n",
    "user_recs = model.recommendForAllUsers(5)\n",
    "\n",
    "# Display recommendations\n",
    "user_recs.show(5, truncate=False)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb9996d-a880-4b88-9b4d-b775432b6a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
